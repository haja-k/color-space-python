{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffebc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12ef0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyimagesearch.livenessnet import LivenessNet\n",
    "from ok.mask import LivenessNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da0944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "BS = 8\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3577b5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "dataset =  (\"../dataset/\")\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2bdc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename, load the image and\n",
    "\t# resize it to be a fixed 32x32 pixels, ignoring aspect ratio\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (32, 32))\n",
    "\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d70383c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into a NumPy array, then preprocess it by scaling\n",
    "# all pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "661f735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels (which are currently strings) as integers and then\n",
    "# one-hot encode them\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = to_categorical(labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0053bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, random_state=42)\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "933b84a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsisains/Documents/Projects/Current/ekyc-2022/liveness-res/color/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = LivenessNet.build(width=32, height=32, depth=3,\n",
    "\tclasses=len(le.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5088ae82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network for 50 epochs...\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 2s 45ms/step - loss: 1.1031 - accuracy: 0.5127 - val_loss: 0.7601 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 1.0033 - accuracy: 0.5380 - val_loss: 0.8723 - val_accuracy: 0.1250\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 1.0807 - accuracy: 0.4937 - val_loss: 0.9684 - val_accuracy: 0.1250\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 1.0350 - accuracy: 0.5253 - val_loss: 1.0257 - val_accuracy: 0.1250\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.9105 - accuracy: 0.5562 - val_loss: 1.1002 - val_accuracy: 0.1250\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.9291 - accuracy: 0.5759 - val_loss: 1.1263 - val_accuracy: 0.1250\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.8656 - accuracy: 0.6203 - val_loss: 1.1766 - val_accuracy: 0.1250\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.9322 - accuracy: 0.5688 - val_loss: 1.1610 - val_accuracy: 0.1250\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.9644 - accuracy: 0.5759 - val_loss: 1.1359 - val_accuracy: 0.1250\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.8996 - accuracy: 0.5633 - val_loss: 1.0985 - val_accuracy: 0.1250\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.8901 - accuracy: 0.5949 - val_loss: 1.0464 - val_accuracy: 0.1786\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.8263 - accuracy: 0.6013 - val_loss: 1.0193 - val_accuracy: 0.2143\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.8260 - accuracy: 0.5949 - val_loss: 1.0166 - val_accuracy: 0.2143\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.8512 - accuracy: 0.6329 - val_loss: 0.9965 - val_accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.8109 - accuracy: 0.6329 - val_loss: 0.9855 - val_accuracy: 0.2857\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.8743 - accuracy: 0.5823 - val_loss: 0.9960 - val_accuracy: 0.2857\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.8214 - accuracy: 0.6013 - val_loss: 0.9656 - val_accuracy: 0.3571\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7702 - accuracy: 0.6709 - val_loss: 0.9837 - val_accuracy: 0.3036\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6773 - accuracy: 0.7278 - val_loss: 0.9574 - val_accuracy: 0.2857\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7873 - accuracy: 0.6013 - val_loss: 0.9516 - val_accuracy: 0.3571\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.7505 - accuracy: 0.6392 - val_loss: 0.9099 - val_accuracy: 0.4107\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6879 - accuracy: 0.6562 - val_loss: 0.8952 - val_accuracy: 0.4464\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.8022 - accuracy: 0.6266 - val_loss: 0.7777 - val_accuracy: 0.5714\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.7830 - accuracy: 0.5633 - val_loss: 0.7668 - val_accuracy: 0.5179\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7126 - accuracy: 0.6772 - val_loss: 0.7467 - val_accuracy: 0.5357\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.6427 - accuracy: 0.6962 - val_loss: 0.7284 - val_accuracy: 0.5714\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6718 - accuracy: 0.7405 - val_loss: 0.7141 - val_accuracy: 0.6071\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7249 - accuracy: 0.6582 - val_loss: 0.6289 - val_accuracy: 0.6786\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6133 - accuracy: 0.6899 - val_loss: 0.6089 - val_accuracy: 0.7143\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6876 - accuracy: 0.6899 - val_loss: 0.5788 - val_accuracy: 0.7321\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7061 - accuracy: 0.7089 - val_loss: 0.5909 - val_accuracy: 0.7321\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6683 - accuracy: 0.7152 - val_loss: 0.5788 - val_accuracy: 0.7321\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6552 - accuracy: 0.7089 - val_loss: 0.5657 - val_accuracy: 0.7679\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.7291 - accuracy: 0.6456 - val_loss: 0.5541 - val_accuracy: 0.7679\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6693 - accuracy: 0.6709 - val_loss: 0.5119 - val_accuracy: 0.8214\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6268 - accuracy: 0.7152 - val_loss: 0.4878 - val_accuracy: 0.8214\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6947 - accuracy: 0.6519 - val_loss: 0.4689 - val_accuracy: 0.8571\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6248 - accuracy: 0.6962 - val_loss: 0.4742 - val_accuracy: 0.8393\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6587 - accuracy: 0.6962 - val_loss: 0.4446 - val_accuracy: 0.8393\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6065 - accuracy: 0.7595 - val_loss: 0.4592 - val_accuracy: 0.8214\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.6327 - accuracy: 0.6519 - val_loss: 0.4727 - val_accuracy: 0.8214\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7016 - accuracy: 0.6962 - val_loss: 0.4252 - val_accuracy: 0.8214\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5905 - accuracy: 0.7532 - val_loss: 0.4342 - val_accuracy: 0.8214\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6344 - accuracy: 0.7722 - val_loss: 0.4284 - val_accuracy: 0.8214\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6284 - accuracy: 0.7848 - val_loss: 0.4370 - val_accuracy: 0.8393\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5686 - accuracy: 0.7722 - val_loss: 0.4089 - val_accuracy: 0.8393\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5744 - accuracy: 0.7595 - val_loss: 0.4016 - val_accuracy: 0.8571\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7595 - val_loss: 0.3926 - val_accuracy: 0.8571\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5439 - accuracy: 0.7785 - val_loss: 0.3933 - val_accuracy: 0.8750\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5345 - accuracy: 0.7658 - val_loss: 0.3886 - val_accuracy: 0.8750\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.98      0.88      0.92        49\n",
      "        real       0.50      0.86      0.63         7\n",
      "\n",
      "    accuracy                           0.88        56\n",
      "   macro avg       0.74      0.87      0.78        56\n",
      "weighted avg       0.92      0.88      0.89        56\n",
      "\n",
      "[INFO] serializing network to 'liveness.model'...\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS, epochs=EPOCHS)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=BS)\n",
    "report = (classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=le.classes_))\n",
    "print(report)\n",
    "# print(classification_report(testY.argmax(axis=1),\n",
    "# \tpredictions.argmax(axis=1), target_names=le.classes_))\n",
    "# save the network to disk\n",
    "model_path =  \"liveness.model\" #specify path\n",
    "print(\"[INFO] serializing network to '{}'...\".format(model_path))\n",
    "model.save(model_path, save_format=\"h5\")\n",
    "# save the label encoder to disk\n",
    "f = open(\"./le.pickle\", \"wb\")  #specify directory\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "060cf585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsisains/Documents/Projects/Current/ekyc-2022/liveness-res/color/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "plot = str('plot.png')\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059584a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
